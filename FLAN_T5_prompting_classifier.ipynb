{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### This notebook was run on Google Colab as I needed more than 8GB of VRAM to run Flan-T5-xl. Hence some of the file paths are specific to my Google Drive, so may not run correctly on another machine."
      ],
      "metadata": {
        "id": "gYDplhfAKLK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLj_BxvGGze9",
        "outputId": "52f670de-dd88-4d2e-a7b5-e48635464b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install torch\n",
        "!pip install datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SC9nM-LiHZqb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-uBkX8jItRl",
        "outputId": "cf6208ad-0f00-41b0-bda4-f0363a937e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/NLP_prompting')\n",
        "\n",
        "from fnc_dataset import FNCDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load FLAN T5 Model"
      ],
      "metadata": {
        "id": "imVdtMKmpgeX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "f8ec5a02c08d4d81922e8619216ff980",
            "fac442be630c4e2d90b368d9c77ce3c3",
            "95f9b066616d46298527731bf80e976a",
            "81621f8c4e1944d7ab5352229ec1f3c5",
            "f3e2c8fcb1954b15aa5adc8ca781977d",
            "7ca720ef17284d4db645c8d62459ca71",
            "c754363baf674d53bcd869d9b9ff1af7",
            "233378dd77904060bd63d5cd182dd93b",
            "7715142c06674ccd81987894bc8b7ec3",
            "4987cdcb351949c9bddab23da3638278",
            "9870610373244e2eac75ca90365fc60e"
          ]
        },
        "id": "e6idKlyeGmws",
        "outputId": "280ef8c4-e128-4d61-aad3-672db9b15b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8ec5a02c08d4d81922e8619216ff980"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bf9507bf430>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#load the Flan-T5-xl model\n",
        "modelName = \"google/flan-t5-xl\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(modelName).to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelName, use_fast=True)\n",
        "\n",
        "#move model to gpu, set seed for reproducibility\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Prompt\n",
        "## Measure Performance on Competition Set"
      ],
      "metadata": {
        "id": "u49s2Sp4psKZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvezyGjtJ3sL",
        "outputId": "b527092a-5d59-45b1-c0aa-141b1518f36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25413 entries in the dataset\n",
            "Overall Accuracy: 86.88860032266949\n",
            "Accuracy for 'agree': 25.64%\n",
            "Accuracy for 'disagree': 52.94%\n",
            "Accuracy for 'discuss': 66.44%\n",
            "Accuracy for 'unrelated': 99.50%\n",
            "totals encountered per class: {'agree': 1903, 'disagree': 697, 'discuss': 4464, 'unrelated': 18349}\n",
            "Wrong answer set: {'discuss', 'disagree', 'unrelated', 'agree'}\n"
          ]
        }
      ],
      "source": [
        "batchSize = 50\n",
        "\n",
        "stanceMapping = {\n",
        "    \"agree\": 0,\n",
        "    \"disagree\": 1,\n",
        "    \"discuss\": 2,\n",
        "    \"unrelated\": 3\n",
        "}\n",
        "\n",
        "reverseStanceMapping = {value: key for key, value in stanceMapping.items()}\n",
        "\n",
        "\n",
        "def classify_relationship_batch(headlineBodyPairs, batchSize):\n",
        "    results = []\n",
        "    for i in range(0, len(headlineBodyPairs), batchSize):\n",
        "        batch = headlineBodyPairs[i: i + batchSize]\n",
        "\n",
        "        promptList = []\n",
        "        for headline, articleBody in batch:\n",
        "            prompt = (f\"\"\"\n",
        "Classify the relationship between the following headline and article body into one of these categories: 'agree', 'disagree', 'discuss', or 'unrelated'.\n",
        "\n",
        "Examples:\n",
        "1.\n",
        "Headline: \"New study shows cats reduce stress levels\"\n",
        "Article Body: \"A recent scientific study confirms that spending time with cats can significantly reduce stress.\"\n",
        "Answer: agree\n",
        "\n",
        "2.\n",
        "Headline: \"Climate change is a hoax\"\n",
        "Article Body: \"Scientists around the globe provide evidence that climate change is real and caused by human activity.\"\n",
        "Answer: disagree\n",
        "\n",
        "3.\n",
        "Headline: \"Electric cars will replace petrol vehicles by 2035\"\n",
        "Article Body: \"The shift to electric vehicles is gaining momentum, but infrastructure and consumer adoption remain key challenges.\"\n",
        "Answer: discuss\n",
        "\n",
        "4.\n",
        "Headline: \"The Eiffel Tower was built in 1999\"\n",
        "Article Body: \"A new study suggests that drinking coffee can improve cognitive function and extend lifespan.\"\n",
        "Answer: unrelated\n",
        "\n",
        "Now classify the following:\n",
        "Headline: \"{headline}\"\n",
        "Article Body: \"{articleBody}\"\n",
        "\n",
        "Answer with only one category: 'agree', 'disagree', 'discuss', or 'unrelated'.\n",
        "            \"\"\")\n",
        "            promptList.append(prompt)\n",
        "\n",
        "        #tokenise inputs\n",
        "        tokenizedPrompts = tokenizer(promptList, return_tensors=\"pt\", truncation=True, max_length=1024, padding=True).to(device)\n",
        "\n",
        "        #generate outputs, small max_length as we only want one word back\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**tokenizedPrompts, max_length=200)\n",
        "\n",
        "        #decode the outputs for the batch and add to the overall results list\n",
        "        batchResults = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "        results.extend(batchResults)\n",
        "\n",
        "        #free VRAM\n",
        "        del tokenizedPrompts\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def prompting_dataset_to_dataframe(fncDataset):\n",
        "    #merge stance and body dataframes, drop Body ID column, rename columns, map stances to integers\n",
        "    combinedDataframe = fncDataset.headlinesBodiesCombined\n",
        "    combinedDataframe = combinedDataframe.drop(columns=[\"Body ID\"])\n",
        "    combinedDataframe = combinedDataframe.rename(columns={\n",
        "        \"Headline\": \"headline\",\n",
        "        \"Stance\": \"label\",\n",
        "        \"articleBody\": \"body\"\n",
        "    })\n",
        "    combinedDataframe[\"label\"] = combinedDataframe[\"label\"].map(stanceMapping)\n",
        "\n",
        "    print(f\"{len(combinedDataframe)} entries in the dataset\")\n",
        "    return combinedDataframe\n",
        "\n",
        "\n",
        "competitionData = FNCDataset.from_csv(labelledStancesPath=\"/content/drive/MyDrive/NLP_prompting/fnc-1/competition_test_stances.csv\", articlesPath=\"/content/drive/MyDrive/NLP_prompting/fnc-1/competition_test_bodies.csv\")\n",
        "competitionDataframe = prompting_dataset_to_dataframe(competitionData)\n",
        "\n",
        "headlineBodyPairs = list(zip(competitionDataframe[\"headline\"], competitionDataframe[\"body\"]))\n",
        "correctIntLabels = list(competitionDataframe[\"label\"])\n",
        "\n",
        "results = classify_relationship_batch(headlineBodyPairs, batchSize)\n",
        "\n",
        "cleanResults = [result.strip().lower().split(\" \")[-1] for result in results]\n",
        "correctStringLabels = [reverseStanceMapping[correctIntLabel] for correctIntLabel in correctIntLabels]\n",
        "\n",
        "#initialise performance tracking variables\n",
        "classCorrectCounts = {label: 0 for label in stanceMapping.keys()}\n",
        "classTotalCounts = {label: 0 for label in stanceMapping.keys()}\n",
        "wrongResults = set()\n",
        "correctCount = 0\n",
        "\n",
        "#go through the model predictions and count how many are correct for each class\n",
        "for i, cleanResult in enumerate(cleanResults):\n",
        "    correctStringLabel = correctStringLabels[i]\n",
        "    classTotalCounts[correctStringLabel] += 1\n",
        "    if cleanResult == correctStringLabel:\n",
        "        correctCount += 1\n",
        "        classCorrectCounts[correctStringLabel] += 1\n",
        "    else:\n",
        "        wrongResults.add(cleanResult)\n",
        "\n",
        "#print overall accuracy\n",
        "overallAccuracy = correctCount / len(cleanResults) * 100.0\n",
        "print(f\"Overall Accuracy: {overallAccuracy}\")\n",
        "\n",
        "#print class accuracies\n",
        "for label in stanceMapping.keys():\n",
        "    if classTotalCounts[label] > 0:\n",
        "        classAccuracy = classCorrectCounts[label] / classTotalCounts[label] * 100.0\n",
        "        print(f\"Accuracy for '{label}': {classAccuracy:.2f}%\")\n",
        "    else:\n",
        "        print(f\"No samples for class '{label}'.\")\n",
        "\n",
        "print(f\"totals encountered per class: {classTotalCounts}\")\n",
        "print(f\"Wrong answer set: {wrongResults}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8ec5a02c08d4d81922e8619216ff980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fac442be630c4e2d90b368d9c77ce3c3",
              "IPY_MODEL_95f9b066616d46298527731bf80e976a",
              "IPY_MODEL_81621f8c4e1944d7ab5352229ec1f3c5"
            ],
            "layout": "IPY_MODEL_f3e2c8fcb1954b15aa5adc8ca781977d"
          }
        },
        "fac442be630c4e2d90b368d9c77ce3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca720ef17284d4db645c8d62459ca71",
            "placeholder": "​",
            "style": "IPY_MODEL_c754363baf674d53bcd869d9b9ff1af7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "95f9b066616d46298527731bf80e976a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233378dd77904060bd63d5cd182dd93b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7715142c06674ccd81987894bc8b7ec3",
            "value": 2
          }
        },
        "81621f8c4e1944d7ab5352229ec1f3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4987cdcb351949c9bddab23da3638278",
            "placeholder": "​",
            "style": "IPY_MODEL_9870610373244e2eac75ca90365fc60e",
            "value": " 2/2 [00:00&lt;00:00,  2.87it/s]"
          }
        },
        "f3e2c8fcb1954b15aa5adc8ca781977d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca720ef17284d4db645c8d62459ca71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c754363baf674d53bcd869d9b9ff1af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "233378dd77904060bd63d5cd182dd93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7715142c06674ccd81987894bc8b7ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4987cdcb351949c9bddab23da3638278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9870610373244e2eac75ca90365fc60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}